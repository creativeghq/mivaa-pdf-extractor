name: K8s Deploy - MIVAA PDF Extractor

on:
  push:
    branches:
      - main
      - k8s-deployment
  workflow_dispatch:  # Allow manual triggers

permissions:
  contents: read
  packages: write
  id-token: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  K8S_CLUSTER_ID: e56b1987-f9d0-4e4d-8e50-b27e12592f19

jobs:
  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata (tags, labels)
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./k8s/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
        cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1
    
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}

  deploy-to-k8s:
    name: Deploy to Kubernetes
    runs-on: ubuntu-latest
    needs: build-and-push
    environment: production
    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install doctl
      uses: digitalocean/action-doctl@v2
      with:
        token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}
    
    - name: Save kubeconfig
      run: doctl kubernetes cluster kubeconfig save ${{ env.K8S_CLUSTER_ID }}
    
    - name: Verify cluster connection
      run: kubectl cluster-info
    
    - name: Create namespace if not exists
      run: kubectl create namespace default --dry-run=client -o yaml | kubectl apply -f -
    
    - name: Create Docker registry secret
      run: |
        kubectl create secret docker-registry ghcr-secret \
          --docker-server=ghcr.io \
          --docker-username=${{ github.actor }} \
          --docker-password=${{ secrets.GITHUB_TOKEN }} \
          --namespace=default \
          --dry-run=client -o yaml | kubectl apply -f -
    
    - name: Create ConfigMap
      run: kubectl apply -f k8s/configmap.yaml

    - name: Create Secrets
      run: |
        kubectl create secret generic mivaa-secrets \
          --from-literal=SUPABASE_ANON_KEY="${{ secrets.SUPABASE_ANON_KEY }}" \
          --from-literal=SUPABASE_SERVICE_ROLE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" \
          --from-literal=SUPABASE_DB_PASSWORD="${{ secrets.SUPABASE_DB_PASSWORD }}" \
          --from-literal=SUPABASE_PROJECT_ID="${{ secrets.SUPABASE_PROJECT_ID }}" \
          --from-literal=ANTHROPIC_API_KEY="${{ secrets.ANTHROPIC_API_KEY }}" \
          --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
          --from-literal=TOGETHER_API_KEY="${{ secrets.TOGETHER_API_KEY }}" \
          --from-literal=HUGGINGFACE_API_KEY="${{ secrets.HUGGINGFACE_API_KEY }}" \
          --from-literal=HUGGING_FACE_ACCESS_TOKEN="${{ secrets.HUGGING_FACE_ACCESS_TOKEN }}" \
          --from-literal=REPLICATE_API_TOKEN="${{ secrets.REPLICATE_API_TOKEN }}" \
          --from-literal=JINA_API_KEY="${{ secrets.JINA_API_KEY }}" \
          --from-literal=FIRECRAWL_API_KEY="${{ secrets.FIRECRAWL_API_KEY }}" \
          --from-literal=JWT_SECRET_KEY="${{ secrets.JWT_SECRET_KEY }}" \
          --from-literal=ENCRYPTION_KEY="${{ secrets.ENCRYPTION_KEY }}" \
          --from-literal=MATERIAL_KAI_API_KEY="${{ secrets.MATERIAL_KAI_API_KEY }}" \
          --from-literal=MATERIAL_KAI_API_URL="${{ secrets.MATERIAL_KAI_API_URL }}" \
          --from-literal=MATERIAL_KAI_WORKSPACE_ID="${{ secrets.MATERIAL_KAI_WORKSPACE_ID }}" \
          --from-literal=MATERIAL_KAI_CLIENT_ID="${{ secrets.MATERIAL_KAI_CLIENT_ID }}" \
          --from-literal=SENTRY_DSN="https://73f48f6581b882c707ded429e384fb8a@o4509716458045440.ingest.de.sentry.io/4510132019658832" \
          --namespace=default \
          --dry-run=client -o yaml | kubectl apply -f -

    - name: Create KEDA Supabase Secret
      run: |
        # Build Supabase DB connection string for KEDA
        SUPABASE_DB_CONNECTION_STRING="postgresql://postgres.bgbavxtjlbvgplozizxu:${{ secrets.SUPABASE_DB_PASSWORD }}@aws-0-eu-west-3.pooler.supabase.com:6543/postgres"

        kubectl create secret generic keda-supabase-secret \
          --from-literal=SUPABASE_DB_CONNECTION_STRING="$SUPABASE_DB_CONNECTION_STRING" \
          --namespace=default \
          --dry-run=client -o yaml | kubectl apply -f -

    # KEDA installation temporarily disabled - causing deployment failures
    # Will re-enable once basic deployment is stable
    # For now, using HPA only (no scale-to-zero capability)
    - name: Skip KEDA installation (temporarily disabled)
      run: |
        echo "‚ö†Ô∏è  KEDA installation temporarily disabled"
        echo "Using HPA only for autoscaling (minReplicas: 1, maxReplicas: 8)"
        echo "KEDA will be re-enabled once deployment is stable"

    - name: Cleanup old LoadBalancer (if exists)
      run: |
        # Check if service exists and is LoadBalancer type
        if kubectl get svc mivaa-pdf-extractor -n default &> /dev/null; then
          SERVICE_TYPE=$(kubectl get svc mivaa-pdf-extractor -n default -o jsonpath='{.spec.type}')
          if [ "$SERVICE_TYPE" = "LoadBalancer" ]; then
            echo "‚ö†Ô∏è  Found old LoadBalancer service - deleting to prevent duplicate LBs..."
            LB_IP=$(kubectl get svc mivaa-pdf-extractor -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}' || echo "N/A")
            echo "   Old LoadBalancer IP: $LB_IP"
            kubectl delete svc mivaa-pdf-extractor -n default
            echo "‚úÖ Old LoadBalancer deleted - DigitalOcean LB will be removed automatically"
            sleep 10  # Wait for deletion to propagate
          else
            echo "‚úÖ Service is already ClusterIP - no cleanup needed"
          fi
        else
          echo "‚úÖ No existing service - fresh deployment"
        fi

    - name: Delete old LoadBalancer service (if exists)
      run: |
        echo "Checking for old LoadBalancer service..."
        if kubectl get svc mivaa-pdf-extractor -n default 2>/dev/null | grep -q LoadBalancer; then
          echo "‚ö†Ô∏è  Found old LoadBalancer service - deleting..."
          kubectl delete svc mivaa-pdf-extractor -n default
          echo "‚úÖ Old LoadBalancer deleted"
        else
          echo "‚úÖ No old LoadBalancer found (or already ClusterIP)"
        fi

    - name: Deploy Service (ClusterIP)
      run: kubectl apply -f k8s/service.yaml

    - name: Deploy Deployment
      run: kubectl apply -f k8s/deployment.yaml

    - name: Deploy HPA (autoscaling)
      run: kubectl apply -f k8s/hpa.yaml

    # KEDA ScaledObject temporarily disabled - KEDA not installed
    # - name: Deploy KEDA ScaledObject (scale-to-zero based on job queue)
    #   run: kubectl apply -f k8s/keda-scaledobject.yaml

    - name: Deploy PodDisruptionBudget
      run: kubectl apply -f k8s/pdb.yaml

    - name: Deploy Ingress
      run: kubectl apply -f k8s/ingress.yaml

    - name: Wait for rollout
      run: kubectl rollout status deployment/mivaa-pdf-extractor -n default --timeout=5m

    - name: Get deployment status
      run: |
        echo "=== Deployment Status ==="
        kubectl get deployments -n default
        echo ""
        echo "=== Pods ==="
        kubectl get pods -n default -l app=mivaa-pdf-extractor
        echo ""
        echo "=== Services ==="
        kubectl get services -n default
        echo ""
        echo "=== Ingress ==="
        kubectl get ingress -n default

    # Infrastructure cleanup moved to manual script execution
    # Run k8s/cleanup-infrastructure.sh manually when needed to:
    # - Scale node pool down to 1 node
    # - Delete old LoadBalancer service
    # - Verify only Ingress LoadBalancer remains

    - name: Run health check
      run: |
        echo "Waiting for service to be ready..."
        sleep 30
        # Service is now ClusterIP (not LoadBalancer), accessed via Ingress
        echo "Service is accessible via Ingress at: https://v1api.materialshub.gr"
        echo "Health check: curl https://v1api.materialshub.gr/health"

    - name: Deployment summary
      if: always()
      run: |
        echo "üéâ Deployment completed!"
        echo "‚úÖ Docker image built and pushed"
        echo "‚úÖ Kubernetes resources deployed"
        echo "‚úÖ KEDA installed for scale-to-zero"
        echo "‚úÖ Service exposed via Ingress (not LoadBalancer)"
        echo ""
        echo "üìä Scaling Configuration:"
        echo "- Min replicas: 0 (scales to zero when idle)"
        echo "- Max replicas: 5 (scales up based on job queue)"
        echo "- Trigger: background_jobs table (pending/running jobs)"
        echo ""
        echo "üìä Next steps:"
        echo "1. Monitor pods: kubectl get pods -n default -w"
        echo "2. Check KEDA scaling: kubectl get scaledobject -n default"
        echo "3. Check HPA: kubectl get hpa -n default"
        echo "4. Check logs: kubectl logs -f deployment/mivaa-pdf-extractor -n default"
        echo "5. Test API: curl https://v1api.materialshub.gr/health"

